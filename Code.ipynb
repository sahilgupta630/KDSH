{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "emnmZK0QsIlH"
      },
      "outputs": [],
      "source": [
        "# Add API Keys here\n",
        "GROQ_API_KEY_i_1 = \"...\"\n",
        "GROQ_API_KEY_i_2 = \"...\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzCv0w-evd1t",
        "outputId": "b60adc9e-649d-4ae5-a1a9-e7919180f4f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.9/70.9 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.3/138.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m777.6/777.6 kB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.6/244.6 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.1/320.1 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.6/148.6 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.0/220.0 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m98.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m142.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-adk 1.21.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.39.1 which is incompatible.\n",
            "google-adk 1.21.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-gcp-logging 1.11.0a0 requires opentelemetry-sdk<1.39.0,>=1.35.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
            "plum-dispatch 2.6.0 requires beartype>=0.16.2, but you have beartype 0.15.0 which is incompatible.\n",
            "bigframes 2.31.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.36.0, but you have google-cloud-bigquery 3.29.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install pathway sentence-transformers pandas numpy tqdm openai groq python-dotenv -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoLnIpAauHFD",
        "outputId": "2c4e15d2-f0b5-419e-b166-312e4039f1b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "✅ Dataset found on Drive!\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Verify the path exists\n",
        "import os\n",
        "if os.path.exists(\"/content/drive/MyDrive/KDSH26/Dataset/\"):\n",
        "    print(\"✅ Dataset found on Drive!\")\n",
        "else:\n",
        "    print(\"❌ Path not found. Please check your Drive folder structure.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZWic35DhV2f",
        "outputId": "8c52860a-c316-45c0-ca49-4592fb15fbc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting data_ingestion.py\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# FILE 1: DATA INGESTION\n",
        "# ==========================================\n",
        "%%writefile data_ingestion.py\n",
        "import pathway as pw\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import os\n",
        "from typing import Any\n",
        "\n",
        "# Define Embedding Model Globally\n",
        "EMBEDDING_MODEL_NAME = 'all-MiniLM-L6-v2'\n",
        "GLOBAL_EMBEDDING_MODEL = SentenceTransformer(EMBEDDING_MODEL_NAME)\n",
        "CHUNK_SIZE = 2048\n",
        "OVERLAP = 256\n",
        "\n",
        "class NovelIngestionPipeline:\n",
        "    def __init__(self, data_dir):\n",
        "        self.data_dir = data_dir\n",
        "        self.model = GLOBAL_EMBEDDING_MODEL\n",
        "\n",
        "    @staticmethod\n",
        "    def _split_text_sliding_window(text: str, chunk_size=CHUNK_SIZE, overlap=OVERLAP):\n",
        "        words = text.split()\n",
        "        n_words = len(words)\n",
        "        chunks = []\n",
        "        step = chunk_size - overlap\n",
        "        for i in range(0, n_words, step):\n",
        "            chunk_words = words[i : i + chunk_size]\n",
        "            chunk_text = \" \".join(chunk_words)\n",
        "            relative_position = round(i / n_words, 3) if n_words > 0 else 0.0\n",
        "            chunks.append((chunk_text, relative_position))\n",
        "        return chunks\n",
        "\n",
        "    @pw.udf\n",
        "    def process_document(text: str) -> list[tuple[str, float]]:\n",
        "        return NovelIngestionPipeline._split_text_sliding_window(text)\n",
        "\n",
        "    @pw.udf\n",
        "    def embed_text(text: str) -> list[float]:\n",
        "        return GLOBAL_EMBEDDING_MODEL.encode(text).tolist()\n",
        "\n",
        "    @staticmethod\n",
        "    @pw.udf\n",
        "    def get_metadata(filepath: Any) -> dict:\n",
        "        path_str = str(filepath)\n",
        "        if path_str.startswith('\"') and path_str.endswith('\"'):\n",
        "            path_str = path_str[1:-1]\n",
        "        filename = os.path.basename(str(path_str))\n",
        "        return {'filename': filename}\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    @pw.udf\n",
        "    def get_book_name(filepath: Any) -> str:\n",
        "        \"\"\"\n",
        "        Extracts clean filename (e.g., 'Harry_Potter') without extension.\n",
        "        \"\"\"\n",
        "        path_str = str(filepath)\n",
        "        # Remove JSON quotes if present\n",
        "        if path_str.startswith('\"') and path_str.endswith('\"'):\n",
        "            path_str = path_str[1:-1]\n",
        "\n",
        "        # Get filename (book.txt)\n",
        "        filename = os.path.basename(path_str)\n",
        "\n",
        "        # Split extension (book, .txt) and return just the name\n",
        "        name_only, _ = os.path.splitext(filename)\n",
        "        return name_only\n",
        "\n",
        "    def run_indexing(self):\n",
        "        print(f\"--- Ingesting from {self.data_dir} ---\")\n",
        "        # Read files\n",
        "        files = pw.io.fs.read(self.data_dir, format=\"plaintext\", mode=\"static\", with_metadata=True)\n",
        "\n",
        "        # Extract metadata\n",
        "        documents = files.select(\n",
        "            text=pw.this.data,\n",
        "            # meta=NovelIngestionPipeline.get_metadata(pw.this._metadata[\"path\"])\n",
        "            book_name=NovelIngestionPipeline.get_book_name(pw.this._metadata[\"path\"])\n",
        "        )\n",
        "\n",
        "        # Chunking\n",
        "        chunks = documents.select(\n",
        "            # metadata=pw.this.meta,\n",
        "            pw.this.book_name,\n",
        "            chunk_data=NovelIngestionPipeline.process_document(pw.this.text)\n",
        "        ).flatten(pw.this.chunk_data)\n",
        "\n",
        "        # Formatting\n",
        "        structured_chunks = chunks.select(\n",
        "            # book_name=pw.this.metadata[\"filename\"],\n",
        "            pw.this.book_name,\n",
        "            chunk_text=pw.this.chunk_data[0],\n",
        "            relative_position=pw.this.chunk_data[1]\n",
        "        )\n",
        "\n",
        "        # Embedding\n",
        "        embedded_chunks = structured_chunks.select(\n",
        "            pw.this.book_name,\n",
        "            pw.this.chunk_text,\n",
        "            pw.this.relative_position,\n",
        "            vector=NovelIngestionPipeline.embed_text(pw.this.chunk_text)\n",
        "        )\n",
        "\n",
        "        return pw.debug.table_to_pandas(embedded_chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68r9P-ichZfZ",
        "outputId": "50067a10-7974-4195-b22e-01ae8a74ed6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting query_generator.py\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# FILE 2: QUERY GENERATOR\n",
        "# ==========================================\n",
        "%%writefile query_generator.py\n",
        "import json\n",
        "\n",
        "class BackstoryDecomposer:\n",
        "    def __init__(self, llm_client, model_name):\n",
        "        self.client = llm_client\n",
        "        self.model = model_name\n",
        "\n",
        "    def decompose_backstory(self, backstory_text: str, character_name: str) -> list:\n",
        "        prompt = f\"\"\"\n",
        "        Analyze this backstory for character \"{character_name}\":\n",
        "        \"{backstory_text}\"\n",
        "\n",
        "        Extract 3-5 atomic, verifiable claims (Temporal, Relationship, Location, Trait).\n",
        "        For EACH claim, provide 3 search queries:\n",
        "        1. Keyword search\n",
        "        2. Descriptive search\n",
        "        3. Anti-evidence search (checking for contradiction)\n",
        "\n",
        "        Output JSON format:\n",
        "        {{\n",
        "            \"claims\": [\n",
        "                {{\n",
        "                    \"text\": \"Claim description\",\n",
        "                    \"type\": \"CATEGORY\",\n",
        "                    \"queries\": [\"query1\", \"query2\", \"query3\"]\n",
        "                }}\n",
        "            ]\n",
        "        }}\n",
        "        \"\"\"\n",
        "        try:\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=self.model,\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                response_format={\"type\": \"json_object\"},\n",
        "                temperature=0.1\n",
        "            )\n",
        "            return json.loads(response.choices[0].message.content).get(\"claims\", [])\n",
        "        except Exception as e:\n",
        "            # print(f\"Decomposition Error: {e}\")\n",
        "            os.environ[\"GROQ_KEY_2\"] = GROQ_API_KEY_i_2\n",
        "            self.client = Groq(api_key=os.environ[\"GROQ_KEY_2\"])\n",
        "            # return [{\"text\": backstory_text, \"type\": \"GENERAL\", \"queries\": [backstory_text]}]\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=self.model,\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                response_format={\"type\": \"json_object\"},\n",
        "                temperature=0.1\n",
        "            )\n",
        "            return json.loads(response.choices[0].message.content).get(\"claims\", [])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzawEwjghcQ8",
        "outputId": "3413ad9b-8ebd-4007-a181-581967f135b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting evidence_retrieval.py\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# FILE 3: EVIDENCE RETRIEVAL\n",
        "# ==========================================\n",
        "%%writefile evidence_retrieval.py\n",
        "from sentence_transformers import CrossEncoder, util\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "RERANKER_MODEL_NAME = 'cross-encoder/ms-marco-MiniLM-L-6-v2'\n",
        "\n",
        "class EvidenceRetriever:\n",
        "    def __init__(self, index_df, embedding_model):\n",
        "        # 1. Clean Index\n",
        "        self.index = index_df.reset_index(drop=True)\n",
        "        self.index['book_name'] = self.index['book_name'].fillna('').astype(str)\n",
        "\n",
        "        self.embedder = embedding_model\n",
        "        self.reranker = CrossEncoder(RERANKER_MODEL_NAME)\n",
        "\n",
        "        # --- CRITICAL FIX: FORCE FLOAT32 ---\n",
        "        # Convert Pandas objects (float64) to float32 numpy array for PyTorch compatibility\n",
        "        raw_vectors = np.stack(self.index['vector'].values)\n",
        "        self.vector_stack = raw_vectors.astype(np.float32)\n",
        "\n",
        "    def search(self, claim_data, book_title):\n",
        "        if not book_title or pd.isna(book_title):\n",
        "            return []\n",
        "\n",
        "        # 1. Scope by book\n",
        "        book_mask = self.index['book_name'].str.contains(str(book_title), case=False, regex=False, na=False)\n",
        "        book_idx = self.index[book_mask].index\n",
        "\n",
        "        if len(book_idx) == 0:\n",
        "            return []\n",
        "\n",
        "        # Get vectors for this book (already float32 from init)\n",
        "        book_vectors = self.vector_stack[book_idx]\n",
        "        book_chunks = self.index.loc[book_idx].reset_index(drop=True)\n",
        "\n",
        "        # 2. Multi-query search\n",
        "        candidate_indices = set()\n",
        "        for query in claim_data['queries']:\n",
        "            # Ensure query vector is also float32\n",
        "            query_vec = self.embedder.encode(query).astype(np.float32)\n",
        "\n",
        "            scores = util.cos_sim(query_vec, book_vectors)[0]\n",
        "\n",
        "            if len(book_vectors) == 0: continue\n",
        "\n",
        "            top_k = torch.topk(scores, k=min(15, len(book_vectors))).indices.tolist()\n",
        "            candidate_indices.update(top_k)\n",
        "\n",
        "        if not candidate_indices:\n",
        "            return []\n",
        "\n",
        "        # 3. Select Candidates\n",
        "        candidates = book_chunks.iloc[list(candidate_indices)].copy()\n",
        "\n",
        "        # 4. Rerank\n",
        "        pred_pairs = [(claim_data['text'], row['chunk_text']) for _, row in candidates.iterrows()]\n",
        "        candidates['score'] = self.reranker.predict(pred_pairs)\n",
        "\n",
        "        # 5. Temporal Boost\n",
        "        if claim_data.get('type') == 'TEMPORAL' and 'early' in claim_data['text']:\n",
        "             candidates['score'] += np.where(candidates['relative_position'] < 0.2, 1.0, 0.0)\n",
        "\n",
        "        return candidates.sort_values(by='score', ascending=False).head(5)[['chunk_text', 'score', 'relative_position']].to_dict('records')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5raugO2heq2",
        "outputId": "d03c7fd2-1d64-4af8-b910-dae1adb9bb73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting verification.py\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# FILE 4: Verification\n",
        "# ==========================================\n",
        "%%writefile verification.py\n",
        "import json\n",
        "import time\n",
        "from groq import Groq\n",
        "from groq import RateLimitError\n",
        "\n",
        "class StoryVerifier:\n",
        "    def __init__(self, llm_client, model_name):\n",
        "        self.client = llm_client\n",
        "        self.model = model_name\n",
        "\n",
        "    def verify_backstory(self, claims, retrieval_engine, book_title):\n",
        "        contradiction_found = False\n",
        "        all_rationales = []\n",
        "\n",
        "        for claim in claims:\n",
        "            evidence = retrieval_engine.search(claim, book_title)\n",
        "            if not evidence: continue\n",
        "\n",
        "            evidence_text = \"\\n\".join([f\"- {e['chunk_text']} (Pos: {e['relative_position']})\" for e in evidence])\n",
        "\n",
        "            prompt = f\"\"\"\n",
        "            Task: Check Consistency.\n",
        "            Claim: \"{claim['text']}\"\n",
        "            Evidence from Book:\n",
        "            {evidence_text}\n",
        "\n",
        "            Does the evidence IMPOSSIBLY CONTRADICT the claim?\n",
        "\n",
        "            Return a JSON object with this exact format:\n",
        "            {{\n",
        "                \"verdict\": \"SUPPORT\" or \"CONTRADICT\" or \"NEUTRAL\",\n",
        "                \"confidence\": 0.0 to 1.0,\n",
        "                \"rationale\": \"One sentence explanation\"\n",
        "            }}\n",
        "            \"\"\"\n",
        "            retries = 2\n",
        "            for i in range(retries):\n",
        "                try:\n",
        "                    resp = self.client.chat.completions.create(\n",
        "                        model=self.model,\n",
        "                        messages=[\n",
        "                            {\"role\": \"system\", \"content\": \"You are a strict fact-checker. Output JSON only.\"},\n",
        "                            {\"role\": \"user\", \"content\": prompt}\n",
        "                        ],\n",
        "                        response_format={\"type\": \"json_object\"},\n",
        "                        temperature=0.0\n",
        "                    ).choices[0].message.content\n",
        "\n",
        "                    result = json.loads(resp)\n",
        "\n",
        "                    verdict = result.get(\"verdict\", \"NEUTRAL\").upper()\n",
        "                    confidence = float(result.get(\"confidence\", 0.0))\n",
        "                    rationale = result.get(\"rationale\", \"\")\n",
        "\n",
        "                    if verdict == \"CONTRADICT\" and confidence >= 0.4:\n",
        "                        contradiction_found = True\n",
        "                    all_rationales.append(f\"{rationale}\")\n",
        "                    time.sleep(3)\n",
        "                    break # Break retry loop if successful\n",
        "                except RateLimitError as e:\n",
        "                    # print(f\"Verification Rate Limit Error for claim '{claim['text']}' (attempt {i+1}/{retries}): {e}\")\n",
        "                    print(\"Switching api key\")\n",
        "                    time.sleep(2 ** i + 1) # Exponential backoff with a base of 1 second\n",
        "                    os.environ[\"GROQ_KEY_2\"] = GROQ_API_KEY_i_2\n",
        "                    self.client = Groq(api_key=os.environ[\"GROQ_KEY_2\"])\n",
        "                    continue\n",
        "                except Exception as e:\n",
        "                    print(f\"Verification Error for claim '{claim['text']}': {e}\")\n",
        "                    break # Break retry loop for other errors\n",
        "\n",
        "        if contradiction_found:\n",
        "            return 0, \" | \".join(all_rationales)\n",
        "        return 1, \" | \".join(all_rationales)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qxoufy2LhQwU",
        "outputId": "db078a3e-6b62-4e3b-f263-f0678ef82b81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting validator.py\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# FILE 5: VALIDATOR (ORCHESTRATOR)\n",
        "# ==========================================\n",
        "%%writefile validator.py\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Import modules\n",
        "from query_generator import BackstoryDecomposer\n",
        "from evidence_retrieval import EvidenceRetriever\n",
        "from verification import StoryVerifier\n",
        "from data_ingestion import GLOBAL_EMBEDDING_MODEL\n",
        "\n",
        "TRAIN_CSV = \"/content/drive/MyDrive/KDSH26/Dataset/train.csv\"\n",
        "\n",
        "def map_label(val):\n",
        "    \"\"\"Converts string labels to integers (0/1) robustly.\"\"\"\n",
        "    if pd.isna(val): return 1 # Default to Consistent if missing\n",
        "\n",
        "    # If already number\n",
        "    if isinstance(val, (int, float)):\n",
        "        return int(val)\n",
        "\n",
        "    # If string\n",
        "    s = str(val).lower().strip()\n",
        "    if \"contradict\" in s: return 0\n",
        "    if \"fake\" in s: return 0\n",
        "    if \"consistent\" in s: return 1\n",
        "    if \"true\" in s: return 1\n",
        "\n",
        "    return 1 # Default fallback\n",
        "\n",
        "def run_validation(client, model_name, index_df, limit=None):\n",
        "    if not os.path.exists(TRAIN_CSV):\n",
        "        print(\"❌ Please upload train.csv\")\n",
        "        return pd.DataFrame() # Return empty DataFrame on error\n",
        "\n",
        "    if index_df is None or index_df.empty:\n",
        "        print(\"❌ CRITICAL ERROR: Passed index_df is empty!\")\n",
        "        return pd.DataFrame() # Return empty DataFrame on error\n",
        "\n",
        "    print(f\"--- 2. Initializing Pipeline with Model: {model_name} ---\")\n",
        "\n",
        "    decomposer = BackstoryDecomposer(client, model_name=model_name)\n",
        "    retriever = EvidenceRetriever(index_df, GLOBAL_EMBEDDING_MODEL)\n",
        "    verifier = StoryVerifier(client, model_name=model_name)\n",
        "\n",
        "    df = pd.read_csv(TRAIN_CSV)\n",
        "    if limit: df = df.head(limit)\n",
        "\n",
        "    preds, truths = [], []\n",
        "    ids = [] # To store the IDs\n",
        "    rationales = []\n",
        "\n",
        "    print(f\"--- 3. Validating {len(df)} stories ---\")\n",
        "\n",
        "    for i, row in tqdm(df.iterrows(), total=len(df)):\n",
        "        try:\n",
        "            # --- INPUT SANITIZATION ---\n",
        "            backstory = row.get('content') or row.get('backstory')\n",
        "            book = row.get('book_name') or row.get('Book')\n",
        "            char = row.get('char') or row.get('Character') or \"Unknown\"\n",
        "            # Get ID, prefer 'id' column, otherwise use row index\n",
        "            current_id = row.get('id', row.name)\n",
        "\n",
        "            # --- LABEL HANDLING (FIXED) ---\n",
        "            raw_label = None\n",
        "            if 'label' in row: raw_label = row['label']\n",
        "            elif 'Label' in row: raw_label = row['Label']\n",
        "            elif 'verdict' in row: raw_label = row['verdict']\n",
        "\n",
        "            truth = map_label(raw_label)\n",
        "\n",
        "            # Skip invalid rows\n",
        "            if pd.isna(book) or pd.isna(backstory):\n",
        "                print(f\"⚠️ Row {i} Skipped: Missing book or backstory\")\n",
        "                preds.append(0)\n",
        "                truths.append(truth)\n",
        "                ids.append(current_id) # Append ID even for skipped rows\n",
        "                continue\n",
        "\n",
        "            # 1. Decompose\n",
        "            claims = decomposer.decompose_backstory(backstory, char)\n",
        "\n",
        "            # 2. Verify\n",
        "            pred, rationale = verifier.verify_backstory(claims, retriever, book)\n",
        "\n",
        "            preds.append(pred)\n",
        "            truths.append(truth)\n",
        "            ids.append(current_id) # Append ID\n",
        "            rationales.append(rationale)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n❌ CRASH on Row {i}: {e}\")\n",
        "            preds.append(1)\n",
        "            truths.append(1)\n",
        "            ids.append(current_id) # Append ID for crashed rows\n",
        "\n",
        "    print(\"\\nResults:\")\n",
        "    try:\n",
        "        print(f\"Accuracy: {accuracy_score(truths, preds)}\")\n",
        "        print(classification_report(truths, preds, target_names=[\"Contradiction (0)\", \"Consistent (1)\"]))\n",
        "    except Exception as e:\n",
        "        print(f\"Could not calculate metrics: {e}\")\n",
        "        print(f\"Preds sample: {preds[:5]}\")\n",
        "        print(f\"Truths sample: {truths[:5]}\")\n",
        "\n",
        "    # Create and return the results DataFrame\n",
        "    results_df = pd.DataFrame({\n",
        "        'id': ids,\n",
        "        'truth': truths,\n",
        "        'prediction': preds,\n",
        "        'rationale': rationales\n",
        "    })\n",
        "    return results_df # Modify return value\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "RZ8GvB60ipUz"
      },
      "outputs": [],
      "source": [
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "N-xyWubshjBR",
        "outputId": "e07f69f9-2ab2-456a-cb8e-60368205d074"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<script type=\"esms-options\">{\"shimMode\": true}</script><style>*[data-root-id],\n",
              "*[data-root-id] > * {\n",
              "  box-sizing: border-box;\n",
              "  font-family: var(--jp-ui-font-family);\n",
              "  font-size: var(--jp-ui-font-size1);\n",
              "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
              "}\n",
              "\n",
              "/* Override VSCode background color */\n",
              ".cell-output-ipywidget-background:has(\n",
              "  > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
              "),\n",
              ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
              "  background-color: transparent !important;\n",
              "}\n",
              "</style>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n  const version = '3.7.3'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  const reloading = false;\n  const Bokeh = root.Bokeh;\n  const BK_RE = /^https:\\/\\/cdn\\.bokeh\\.org\\/bokeh\\/(release|dev)\\/bokeh-/;\n  const PN_RE = /^https:\\/\\/cdn\\.holoviz\\.org\\/panel\\/[^/]+\\/dist\\/panel/i;\n\n  // Set a timeout for this load but only if we are not already initializing\n  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, Bokeh, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      // Don't load bokeh if it is still initializing\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      // There is nothing to load\n      run_callbacks();\n      return null;\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error(e) {\n      const src_el = e.srcElement\n      console.error(\"failed to load \" + (src_el.href || src_el.src));\n    }\n\n    const skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'tabulator': 'https://cdn.jsdelivr.net/npm/tabulator-tables@6.3.1/dist/js/tabulator.min', 'moment': 'https://cdn.jsdelivr.net/npm/luxon/build/global/luxon.min'}, 'shim': {}});\n      require([\"tabulator\"], function(Tabulator) {\n        window.Tabulator = Tabulator\n        on_load()\n      })\n      require([\"moment\"], function(moment) {\n        window.moment = moment\n        on_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 2;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    const existing_stylesheets = []\n    const links = document.getElementsByTagName('link')\n    for (let i = 0; i < links.length; i++) {\n      const link = links[i]\n      if (link.href != null) {\n        existing_stylesheets.push(link.href)\n      }\n    }\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const escaped = encodeURI(url)\n      if (existing_stylesheets.indexOf(escaped) !== -1) {\n        on_load()\n        continue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window.Tabulator !== undefined) && (!(window.Tabulator instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.8.4/dist/bundled/datatabulator/tabulator-tables@6.3.1/dist/js/tabulator.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(encodeURI(urls[i]))\n      }\n    }    if (((window.moment !== undefined) && (!(window.moment instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.8.4/dist/bundled/datatabulator/luxon/build/global/luxon.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(encodeURI(urls[i]))\n      }\n    }    var existing_scripts = []\n    const scripts = document.getElementsByTagName('script')\n    for (let i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n        existing_scripts.push(script.src)\n      }\n    }\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const escaped = encodeURI(url)\n      const shouldSkip = skip.includes(escaped) || existing_scripts.includes(escaped)\n      const isBokehOrPanel = BK_RE.test(escaped) || PN_RE.test(escaped)\n      const missingOrBroken = Bokeh == null || Bokeh.Panel == null || (Bokeh.version != version && !Bokeh.versions?.has(version)) || Bokeh.versions?.get(version).Panel == null;\n      if (shouldSkip && !(isBokehOrPanel && missingOrBroken)) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (let i = 0; i < js_modules.length; i++) {\n      const url = js_modules[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      const url = js_exports[name];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.holoviz.org/panel/1.8.4/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\", \"https://cdn.holoviz.org/panel/1.8.4/dist/bundled/datatabulator/tabulator-tables@6.3.1/dist/js/tabulator.min.js\", \"https://cdn.holoviz.org/panel/1.8.4/dist/bundled/datatabulator/luxon/build/global/luxon.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.7.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.7.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.7.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.7.3.min.js\", \"https://cdn.holoviz.org/panel/1.8.4/dist/panel.min.js\"];\n  const js_modules = [];\n  const js_exports = {};\n  const css_urls = [\"https://cdn.holoviz.org/panel/1.8.4/dist/bundled/datatabulator/tabulator-tables@6.3.1/dist/css/tabulator_simple.min.css\"];\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (let i = 0; i < inline_js.length; i++) {\n        try {\n          inline_js[i].call(root, root.Bokeh);\n        } catch(e) {\n          if (!reloading) {\n            throw e;\n          }\n        }\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false;\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      // If the timeout and bokeh was not successfully loaded we reset\n      // everything and try loading again\n      root._bokeh_timeout = Date.now() + 5000;\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      root._bokeh_is_loading = 0;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true;\n      root._bokeh_onload_callbacks = [];\n      const bokeh_loaded = Bokeh != null && ((Bokeh.version === version && Bokeh.Panel) || (Bokeh.versions?.has(version) && Bokeh.versions.get(version).Panel));\n      if (!reloading && !bokeh_loaded) {\n        if (root.Bokeh) {\n          root.Bokeh = undefined;\n        }\n        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, Bokeh, function() {\n        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n        run_inline_js();\n        if (Bokeh != undefined && !reloading) {\n          const NewBokeh = root.Bokeh;\n          if (Bokeh.versions === undefined) {\n            Bokeh.versions = new Map();\n          }\n          if (NewBokeh.version !== Bokeh.version) {\n            Bokeh[NewBokeh.version] = NewBokeh;\n            Bokeh.versions.set(NewBokeh.version, NewBokeh);\n          }\n          root.Bokeh = Bokeh;\n        }\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
            "application/vnd.holoviews_load.v0+json": ""
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        let retries = 0;\n        const open = () => {\n          if (comm.active) {\n            comm.open();\n          } else if (retries > 3) {\n            console.warn('Comm target never activated')\n          } else {\n            retries += 1\n            setTimeout(open, 500)\n          }\n        }\n        if (comm.active) {\n          comm.open();\n        } else {\n          setTimeout(open, 500)\n        }\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        })\n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
            "application/vnd.holoviews_load.v0+json": ""
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.holoviews_exec.v0+json": "",
            "text/html": [
              "<div id='0017debc-59e1-4956-8b65-0d0ac8e1798f'>\n",
              "  <div id=\"e7ba4e5d-62c3-4ecb-98c3-cb95ea5c1c06\" data-root-id=\"0017debc-59e1-4956-8b65-0d0ac8e1798f\" style=\"display: contents;\"></div>\n",
              "</div>\n",
              "<script type=\"application/javascript\">(function(root) {\n",
              "  var docs_json = {\"c5a189ae-fd56-4ddc-bcca-65d2f4472826\":{\"version\":\"3.7.3\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"0017debc-59e1-4956-8b65-0d0ac8e1798f\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"c9a133e8-78e8-474a-8126-153d8e2c6813\",\"attributes\":{\"plot_id\":\"0017debc-59e1-4956-8b65-0d0ac8e1798f\",\"comm_id\":\"1cfce595594a49b18a83441e40324f21\",\"client_comm_id\":\"1e90338def2e4486ae2cfcda7fe95aab\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"start\",\"kind\":\"Any\",\"default\":0},{\"name\":\"end\",\"kind\":\"Any\",\"default\":100},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"ReactiveESM1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"JSComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"ReactComponent1\",\"properties\":[{\"name\":\"use_shadow_dom\",\"kind\":\"Any\",\"default\":true},{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"AnyWidgetComponent1\",\"properties\":[{\"name\":\"use_shadow_dom\",\"kind\":\"Any\",\"default\":true},{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"max_notifications\",\"kind\":\"Any\",\"default\":5},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_rendered\",\"kind\":\"Any\",\"default\":false},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"request_value1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"_synced\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_request_sync\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
              "  var render_items = [{\"docid\":\"c5a189ae-fd56-4ddc-bcca-65d2f4472826\",\"roots\":{\"0017debc-59e1-4956-8b65-0d0ac8e1798f\":\"e7ba4e5d-62c3-4ecb-98c3-cb95ea5c1c06\"},\"root_ids\":[\"0017debc-59e1-4956-8b65-0d0ac8e1798f\"]}];\n",
              "  var docs = Object.values(docs_json)\n",
              "  if (!docs) {\n",
              "    return\n",
              "  }\n",
              "  const version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
              "  async function embed_document(root) {\n",
              "    var Bokeh = get_bokeh(root)\n",
              "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
              "    for (const render_item of render_items) {\n",
              "      for (const root_id of render_item.root_ids) {\n",
              "\tconst id_el = document.getElementById(root_id)\n",
              "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
              "\t  const root_el = id_el.children[0]\n",
              "\t  root_el.id = root_el.id + '-rendered'\n",
              "\t  for (const child of root_el.children) {\n",
              "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
              "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
              "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
              "\t  }\n",
              "\t}\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "  function get_bokeh(root) {\n",
              "    if (root.Bokeh === undefined) {\n",
              "      return null\n",
              "    } else if (root.Bokeh.version !== version) {\n",
              "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(version)) {\n",
              "\treturn null\n",
              "      }\n",
              "      return root.Bokeh.versions.get(version);\n",
              "    } else if (root.Bokeh.version === version) {\n",
              "      return root.Bokeh\n",
              "    }\n",
              "    return null\n",
              "  }\n",
              "  function is_loaded(root) {\n",
              "    var Bokeh = get_bokeh(root)\n",
              "    return (Bokeh != null && Bokeh.Panel !== undefined && ( root.Tabulator !== undefined) && ( root.Tabulator !== undefined))\n",
              "  }\n",
              "  if (is_loaded(root)) {\n",
              "    embed_document(root);\n",
              "  } else {\n",
              "    var attempts = 0;\n",
              "    var timer = setInterval(function(root) {\n",
              "      if (is_loaded(root)) {\n",
              "        clearInterval(timer);\n",
              "        embed_document(root);\n",
              "      } else if (document.readyState == \"complete\") {\n",
              "        attempts++;\n",
              "        if (attempts > 200) {\n",
              "          clearInterval(timer);\n",
              "\t  var Bokeh = get_bokeh(root)\n",
              "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
              "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
              "\t  } else {\n",
              "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
              "\t    embed_document(root)\n",
              "\t  }\n",
              "        }\n",
              "      }\n",
              "    }, 25, root)\n",
              "  }\n",
              "})(window);</script>"
            ]
          },
          "metadata": {
            "application/vnd.holoviews_exec.v0+json": {
              "id": "0017debc-59e1-4956-8b65-0d0ac8e1798f"
            }
          },
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "WARNING:pathway_engine.connectors.monitoring:FileSystem(/content/drive/MyDrive/KDSH26/Dataset/Books): Closing the data source\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📚 Starting Ingestion...\n",
            "--- Ingesting from /content/drive/MyDrive/KDSH26/Dataset/Books ---\n",
            "✅ Ingestion Complete. Index contains 59486 chunks.\n",
            "                                              book_name  \\\n",
            "^JVJ78A1Y4MSM4WA3RKD1J00200  In search of the castaways   \n",
            "^6HK4KKG56ESR1PGDV3SJ8P0500  In search of the castaways   \n",
            "\n",
            "                                                                    chunk_text  \\\n",
            "^JVJ78A1Y4MSM4WA3RKD1J00200  It took place about eleven o'clock, resembling...   \n",
            "^6HK4KKG56ESR1PGDV3SJ8P0500  Suddenly he stopped, and almost recoiled. He t...   \n",
            "\n",
            "                             relative_position  \\\n",
            "^JVJ78A1Y4MSM4WA3RKD1J00200                0.0   \n",
            "^6HK4KKG56ESR1PGDV3SJ8P0500                0.0   \n",
            "\n",
            "                                                                        vector  \n",
            "^JVJ78A1Y4MSM4WA3RKD1J00200  (-0.02711505815386772, 0.04670959338545799, 0....  \n",
            "^6HK4KKG56ESR1PGDV3SJ8P0500  (0.10211095958948135, -0.032617032527923584, 0...  \n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# INGESTION STEP (RUN ONCE)\n",
        "# ==========================================\n",
        "from data_ingestion import NovelIngestionPipeline\n",
        "import sys\n",
        "\n",
        "# 1. Clear cached modules to ensure updates apply\n",
        "if 'data_ingestion' in sys.modules: del sys.modules['data_ingestion']\n",
        "from data_ingestion import NovelIngestionPipeline\n",
        "\n",
        "# 2. Define your path\n",
        "BOOKS_DIR = \"/content/drive/MyDrive/KDSH26/Dataset/Books\"\n",
        "\n",
        "# 3. Run Ingestion\n",
        "print(\"📚 Starting Ingestion...\")\n",
        "ingestion_pipeline = NovelIngestionPipeline(BOOKS_DIR)\n",
        "index_df = ingestion_pipeline.run_indexing()\n",
        "\n",
        "print(f\"✅ Ingestion Complete. Index contains {len(index_df)} chunks.\")\n",
        "print(index_df.head(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4iuVw-h-oGo6"
      },
      "outputs": [],
      "source": [
        "index_df.to_csv(\"index_data.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Qa9W9-Cjo3hw",
        "outputId": "4bc9afff-604e-4823-e968-6aba3293da97"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_089f371d-8401-4081-a80d-da881956301c\", \"index_data.csv\", 507122926)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# from google.colab import files\n",
        "# files.download('index_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 866
        },
        "id": "SHAC6sIUmsm_",
        "outputId": "93c1035f-6132-4dae-b53f-249bdb7b77f0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"index_df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"book_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"The Count of Monte Cristo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chunk_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"body to the most violent exercises, my soul to the bitterest trials; I\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"relative_position\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vector\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          [\n            0.057381417602300644,\n            0.041833147406578064,\n            0.028476987034082413,\n            0.02512376382946968,\n            -0.025134794414043427,\n            0.03258340060710907,\n            0.11921796202659607,\n            -0.013835467398166656,\n            0.024795742705464363,\n            0.03648034855723381,\n            -0.02645907737314701,\n            0.003698233747854829,\n            -0.0349467471241951,\n            0.009424420073628426,\n            0.08264171332120895,\n            -0.04534970596432686,\n            0.05517028644680977,\n            0.02813079208135605,\n            -0.019178761169314384,\n            0.07359399646520615,\n            -0.09958330541849136,\n            0.07944190502166748,\n            0.07962940633296967,\n            0.048250358551740646,\n            -0.08782429993152618,\n            0.053291309624910355,\n            -0.00630303006619215,\n            0.05650893598794937,\n            0.012204201892018318,\n            -0.0717942863702774,\n            0.027166098356246948,\n            -0.03252888098359108,\n            -0.02424749732017517,\n            0.0047463830560445786,\n            0.005591943394392729,\n            -0.01861022599041462,\n            0.015176967717707157,\n            -0.03560658544301987,\n            0.00368718639947474,\n            -0.009879237040877342,\n            -0.029132964089512825,\n            -0.009966989979147911,\n            0.03502212092280388,\n            0.025853784754872322,\n            0.07461672276258469,\n            -0.016937939450144768,\n            -0.044592808932065964,\n            -0.044051531702280045,\n            0.009148020297288895,\n            -0.0527305044233799,\n            -0.018998349085450172,\n            -0.02444629929959774,\n            -0.04037833586335182,\n            0.07442209124565125,\n            -0.022659024223685265,\n            -0.09117012470960617,\n            0.041327591985464096,\n            0.059414710849523544,\n            0.0014505168655887246,\n            0.02472558431327343,\n            0.023555975407361984,\n            0.030782166868448257,\n            0.025267720222473145,\n            0.002380332676693797,\n            -0.0009960446041077375,\n            -0.04160144552588463,\n            0.1250150054693222,\n            0.005061395466327667,\n            0.015570647083222866,\n            0.06356070190668106,\n            -0.020959706977009773,\n            -0.06564273685216904,\n            0.027652336284518242,\n            0.0076174046844244,\n            -0.05642655864357948,\n            0.03173847123980522,\n            -0.028824375942349434,\n            -0.09260724484920502,\n            -0.018445082008838654,\n            0.015554578974843025,\n            0.002701321616768837,\n            -0.008757476694881916,\n            -0.036393094807863235,\n            -0.020055275410413742,\n            -0.09195448458194733,\n            0.01375515479594469,\n            0.018101835623383522,\n            0.0033232527785003185,\n            0.05140199512243271,\n            0.04418175294995308,\n            -0.04547252506017685,\n            0.017526697367429733,\n            0.03986138850450516,\n            0.06870222091674805,\n            -0.05708418786525726,\n            0.04558917507529259,\n            -0.05266633629798889,\n            -0.05626338720321655,\n            -0.05072813108563423,\n            0.0809980034828186,\n            -0.00568764703348279,\n            -0.007579063531011343,\n            -0.003694148501381278,\n            0.057042744010686874,\n            -0.007363385055214167,\n            -0.06240440160036087,\n            -0.07027000933885574,\n            -0.08085247129201889,\n            -0.04844819754362106,\n            0.021631989628076553,\n            0.000230812729569152,\n            -0.06401163339614868,\n            0.01627744920551777,\n            -0.012571514584124088,\n            0.021965134888887405,\n            0.08246695250272751,\n            -0.024584373459219933,\n            0.019274629652500153,\n            -0.006649547256529331,\n            0.06276937574148178,\n            0.012855030596256256,\n            -0.04248787462711334,\n            -0.002330448478460312,\n            0.014130174182355404,\n            -0.0489150695502758,\n            -0.06414801627397537,\n            -0.06989594548940659,\n            -5.414218246660005e-33,\n            0.022151457145810127,\n            -0.10431983321905136,\n            0.08921126276254654,\n            0.04115249216556549,\n            -0.01589258387684822,\n            -0.050448670983314514,\n            -0.06909560412168503,\n            -0.01490921899676323,\n            0.05233289301395416,\n            0.028286311775445938,\n            -0.0417170450091362,\n            -0.03724877908825874,\n            0.04872044920921326,\n            0.06156890094280243,\n            -0.02476956695318222,\n            -0.05539514869451523,\n            -0.1536908596754074,\n            0.05124099180102348,\n            0.003185978392139077,\n            -0.009266669861972332,\n            -0.031964175403118134,\n            -0.034375183284282684,\n            -0.023549383506178856,\n            0.008660303428769112,\n            -0.030873440206050873,\n            0.041416607797145844,\n            0.016917787492275238,\n            -0.03343096747994423,\n            -0.029675669968128204,\n            -0.006029945332556963,\n            -0.03685300797224045,\n            0.011042101308703423,\n            0.045853305608034134,\n            -0.02720450982451439,\n            0.053730569779872894,\n            0.04435347765684128,\n            0.015786323696374893,\n            -0.03713604807853699,\n            -0.05326809734106064,\n            -0.0011471494799479842,\n            0.05323100462555885,\n            0.05154697224497795,\n            0.054841525852680206,\n            -0.03790149837732315,\n            0.11021239310503006,\n            -0.00021120478049851954,\n            -0.06319377571344376,\n            -0.004383694380521774,\n            -0.025173652917146683,\n            -0.0005900404648855329,\n            0.008623788133263588,\n            0.04642396420240402,\n            0.11721877008676529,\n            -0.009613363072276115,\n            0.06932254135608673,\n            -0.0017077771481126547,\n            -0.04594718664884567,\n            0.01838742010295391,\n            -0.011014030314981937,\n            0.025383656844496727,\n            0.02494017966091633,\n            -0.032714881002902985,\n            -0.02417592890560627,\n            -0.0019150630105286837,\n            -0.092073954641819,\n            -0.024701708927750587,\n            -0.07888783514499664,\n            -0.06126714125275612,\n            0.0003930618695449084,\n            -0.0029146401211619377,\n            -0.09995029121637344,\n            0.07012440264225006,\n            0.008986574597656727,\n            -0.07898686081171036,\n            0.01561546977609396,\n            -0.030146177858114243,\n            0.008140410296618938,\n            -0.008646237663924694,\n            -0.09219632297754288,\n            -0.05715664476156235,\n            0.06291770935058594,\n            0.043030574917793274,\n            -0.028985420241951942,\n            0.10184814035892487,\n            0.1331971436738968,\n            0.016957825049757957,\n            0.006227654870599508,\n            -0.19858333468437195,\n            -0.016003359109163284,\n            0.06273749470710754,\n            -0.09689392149448395,\n            -0.04143812134861946,\n            0.054287318140268326,\n            0.038006607443094254,\n            -0.0492146871984005,\n            4.2433274255891255e-33,\n            0.038794223219156265,\n            -0.03712301701307297,\n            -0.037558168172836304,\n            0.09402861446142197,\n            0.07197950780391693,\n            -0.03405747562646866,\n            -0.05404699221253395,\n            -0.014261022210121155,\n            0.008741205558180809,\n            0.048778727650642395,\n            0.019072022289037704,\n            -0.01105435099452734,\n            0.002399954479187727,\n            0.020548591390252113,\n            0.04446705803275108,\n            -0.04994364455342293,\n            0.026071252301335335,\n            -0.02022649720311165,\n            -0.046162720769643784,\n            0.024489223957061768,\n            -0.03500227630138397,\n            0.0748625099658966,\n            0.04669742286205292,\n            -0.05398108437657356,\n            -0.008002428337931633,\n            -0.020045604556798935,\n            0.04152541235089302,\n            0.0165777076035738,\n            0.027069266885519028,\n            0.02906198427081108,\n            0.07727126032114029,\n            0.03696800395846367,\n            -0.0370447002351284,\n            -0.02193625271320343,\n            0.0013813385739922523,\n            0.05358396843075752,\n            0.01811336725950241,\n            0.07208152115345001,\n            -0.02478007972240448,\n            -0.0007621641852892935,\n            -0.031640131026506424,\n            0.01946091093122959,\n            -0.002088356064632535,\n            0.06835953891277313,\n            -0.0016029292019084096,\n            -0.01749034784734249,\n            -0.013500945642590523,\n            0.0028584161773324013,\n            -0.02223063074052334,\n            0.011574060656130314,\n            -0.004615753423422575,\n            -0.05597358196973801,\n            -0.045931968837976456,\n            0.034621160477399826,\n            0.13610133528709412,\n            -0.056151192635297775,\n            0.010295093059539795,\n            -0.07752154767513275,\n            -0.03977144509553909,\n            -0.036695245653390884,\n            -0.055837757885456085,\n            0.059661999344825745,\n            -0.06065559387207031,\n            0.09911946952342987,\n            0.06335620582103729,\n            0.06881405413150787,\n            -0.09001835435628891,\n            0.0063897352665662766,\n            -0.13228510320186615,\n            0.06003904342651367,\n            -0.10634351521730423,\n            0.052075762301683426,\n            -0.03557189181447029,\n            0.03254735469818115,\n            -0.007652268745005131,\n            -0.015210929326713085,\n            0.03492439165711403,\n            -0.016551362350583076,\n            0.026506276801228523,\n            -0.04495300352573395,\n            -0.03277456760406494,\n            -0.04474502429366112,\n            -0.013979988172650337,\n            0.031081615015864372,\n            -0.03306875750422478,\n            0.09230071306228638,\n            -0.08606203645467758,\n            0.03013639897108078,\n            -0.004705219995230436,\n            -0.0008882561232894659,\n            0.01159112248569727,\n            -0.020169701427221298,\n            0.04348623752593994,\n            -0.04398246482014656,\n            0.0448572002351284,\n            -2.0680742451872902e-08,\n            -0.036210548132658005,\n            -0.01591964066028595,\n            -0.02078867144882679,\n            0.056228432804346085,\n            0.008195956237614155,\n            0.11349871754646301,\n            0.04592374339699745,\n            -0.021457325667142868,\n            -0.019050786271691322,\n            0.05661999434232712,\n            0.10633143037557602,\n            0.02490912564098835,\n            0.11578665673732758,\n            0.10562083125114441,\n            -0.011119142174720764,\n            0.018161648884415627,\n            0.0023870826698839664,\n            0.003603545716032386,\n            -0.08829709887504578,\n            -0.053644876927137375,\n            -0.032768573611974716,\n            -0.0029234513640403748,\n            0.08195262402296066,\n            -0.10054634511470795,\n            -0.02474445104598999,\n            -0.06426262855529785,\n            0.002588954521343112,\n            0.014413697645068169,\n            -0.028888361528515816,\n            0.10931012034416199,\n            0.07067624479532242,\n            -0.0408816933631897,\n            -0.041278813034296036,\n            -0.019130682572722435,\n            -0.061035752296447754,\n            -0.012890961021184921,\n            0.03965863585472107,\n            0.03527916595339775,\n            -0.08450929820537567,\n            0.0446796752512455,\n            -0.026129886507987976,\n            0.020319383591413498,\n            0.060091424733400345,\n            -0.0026547100860625505,\n            -0.009764565154910088,\n            -0.08097723871469498,\n            -0.029884029179811478,\n            -2.99405674013542e-05,\n            0.01591458171606064,\n            -0.030058205127716064,\n            0.04087505862116814,\n            -0.014047649689018726,\n            0.01908046379685402,\n            0.06995067000389099,\n            0.0360250324010849,\n            0.10130631178617477,\n            -0.03296356275677681,\n            0.048809170722961426,\n            -0.08257341384887695,\n            0.04357454925775528,\n            0.17620381712913513,\n            -0.009193094447255135,\n            -0.03722383826971054,\n            -0.0523395761847496\n          ]\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-d4d6a9d2-79e9-4328-bf53-5b936e85799e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>book_name</th>\n",
              "      <th>chunk_text</th>\n",
              "      <th>relative_position</th>\n",
              "      <th>vector</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>^V9KSSV7K7W5D2FBDAY7YMXQEZW</th>\n",
              "      <td>The Count of Monte Cristo</td>\n",
              "      <td>“Shall my father be informed of your wish?”</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(0.01833954080939293, 0.13470959663391113, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>^S4B4Q7WR35EABJZTBWWAZSQHZW</th>\n",
              "      <td>The Count of Monte Cristo</td>\n",
              "      <td>turn. During this time, the jeweller made the ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(-0.03794711083173752, 0.03132128342986107, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>^4X87FSK05Y8MEN5KCFETRZ7PZW</th>\n",
              "      <td>The Count of Monte Cristo</td>\n",
              "      <td>mind rendered him apt at all kinds of calculat...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(0.07306800037622452, 0.08524415642023087, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>^3CJA3X3AK164CGGKEF8XHPFPZW</th>\n",
              "      <td>The Count of Monte Cristo</td>\n",
              "      <td>“Because, my dear fellow, you understand one m...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(0.06627766788005829, 0.09183977544307709, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>^7KC0KV919F6S1BGE984NPAQRZW</th>\n",
              "      <td>The Count of Monte Cristo</td>\n",
              "      <td>capable with the utmost precision to accommoda...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(0.004322108346968889, 0.018124185502529144, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>^SN7VN9QVHN26X99M6VSVPRQTZW</th>\n",
              "      <td>The Count of Monte Cristo</td>\n",
              "      <td>Arrived in his bedroom, the count motioned to ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(0.06660859286785126, 0.0019102210644632578, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>^W1870W3P2HJVY8M5XH69GFZWZW</th>\n",
              "      <td>The Count of Monte Cristo</td>\n",
              "      <td>corner of the Rue Coq-Héron.”</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(0.008851798251271248, 0.08421550691127777, -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>^V516W801HT37DBDTGVDW8WZWZW</th>\n",
              "      <td>The Count of Monte Cristo</td>\n",
              "      <td>“I have long wished it; he is my only remainin...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(-0.04940061643719673, 0.13652947545051575, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>^K16VNBEFECM55EKRC019B3ZYZW</th>\n",
              "      <td>The Count of Monte Cristo</td>\n",
              "      <td>body to the most violent exercises, my soul to...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(0.057381417602300644, 0.041833147406578064, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>^8VJ83FAS3ZAVFCV8MNZQDP7ZZW</th>\n",
              "      <td>The Count of Monte Cristo</td>\n",
              "      <td>Besides, what is required of a young man in Pa...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(0.11163623631000519, 0.07168464362621307, 0.0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d4d6a9d2-79e9-4328-bf53-5b936e85799e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d4d6a9d2-79e9-4328-bf53-5b936e85799e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d4d6a9d2-79e9-4328-bf53-5b936e85799e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-49fcdade-418d-4b26-a7f9-2b50f5e55c9b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-49fcdade-418d-4b26-a7f9-2b50f5e55c9b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-49fcdade-418d-4b26-a7f9-2b50f5e55c9b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                             book_name  \\\n",
              "^V9KSSV7K7W5D2FBDAY7YMXQEZW  The Count of Monte Cristo   \n",
              "^S4B4Q7WR35EABJZTBWWAZSQHZW  The Count of Monte Cristo   \n",
              "^4X87FSK05Y8MEN5KCFETRZ7PZW  The Count of Monte Cristo   \n",
              "^3CJA3X3AK164CGGKEF8XHPFPZW  The Count of Monte Cristo   \n",
              "^7KC0KV919F6S1BGE984NPAQRZW  The Count of Monte Cristo   \n",
              "^SN7VN9QVHN26X99M6VSVPRQTZW  The Count of Monte Cristo   \n",
              "^W1870W3P2HJVY8M5XH69GFZWZW  The Count of Monte Cristo   \n",
              "^V516W801HT37DBDTGVDW8WZWZW  The Count of Monte Cristo   \n",
              "^K16VNBEFECM55EKRC019B3ZYZW  The Count of Monte Cristo   \n",
              "^8VJ83FAS3ZAVFCV8MNZQDP7ZZW  The Count of Monte Cristo   \n",
              "\n",
              "                                                                    chunk_text  \\\n",
              "^V9KSSV7K7W5D2FBDAY7YMXQEZW        “Shall my father be informed of your wish?”   \n",
              "^S4B4Q7WR35EABJZTBWWAZSQHZW  turn. During this time, the jeweller made the ...   \n",
              "^4X87FSK05Y8MEN5KCFETRZ7PZW  mind rendered him apt at all kinds of calculat...   \n",
              "^3CJA3X3AK164CGGKEF8XHPFPZW  “Because, my dear fellow, you understand one m...   \n",
              "^7KC0KV919F6S1BGE984NPAQRZW  capable with the utmost precision to accommoda...   \n",
              "^SN7VN9QVHN26X99M6VSVPRQTZW  Arrived in his bedroom, the count motioned to ...   \n",
              "^W1870W3P2HJVY8M5XH69GFZWZW                      corner of the Rue Coq-Héron.”   \n",
              "^V516W801HT37DBDTGVDW8WZWZW  “I have long wished it; he is my only remainin...   \n",
              "^K16VNBEFECM55EKRC019B3ZYZW  body to the most violent exercises, my soul to...   \n",
              "^8VJ83FAS3ZAVFCV8MNZQDP7ZZW  Besides, what is required of a young man in Pa...   \n",
              "\n",
              "                             relative_position  \\\n",
              "^V9KSSV7K7W5D2FBDAY7YMXQEZW                0.0   \n",
              "^S4B4Q7WR35EABJZTBWWAZSQHZW                0.0   \n",
              "^4X87FSK05Y8MEN5KCFETRZ7PZW                0.0   \n",
              "^3CJA3X3AK164CGGKEF8XHPFPZW                0.0   \n",
              "^7KC0KV919F6S1BGE984NPAQRZW                0.0   \n",
              "^SN7VN9QVHN26X99M6VSVPRQTZW                0.0   \n",
              "^W1870W3P2HJVY8M5XH69GFZWZW                0.0   \n",
              "^V516W801HT37DBDTGVDW8WZWZW                0.0   \n",
              "^K16VNBEFECM55EKRC019B3ZYZW                0.0   \n",
              "^8VJ83FAS3ZAVFCV8MNZQDP7ZZW                0.0   \n",
              "\n",
              "                                                                        vector  \n",
              "^V9KSSV7K7W5D2FBDAY7YMXQEZW  (0.01833954080939293, 0.13470959663391113, 0.0...  \n",
              "^S4B4Q7WR35EABJZTBWWAZSQHZW  (-0.03794711083173752, 0.03132128342986107, 0....  \n",
              "^4X87FSK05Y8MEN5KCFETRZ7PZW  (0.07306800037622452, 0.08524415642023087, 0.0...  \n",
              "^3CJA3X3AK164CGGKEF8XHPFPZW  (0.06627766788005829, 0.09183977544307709, 0.0...  \n",
              "^7KC0KV919F6S1BGE984NPAQRZW  (0.004322108346968889, 0.018124185502529144, -...  \n",
              "^SN7VN9QVHN26X99M6VSVPRQTZW  (0.06660859286785126, 0.0019102210644632578, -...  \n",
              "^W1870W3P2HJVY8M5XH69GFZWZW  (0.008851798251271248, 0.08421550691127777, -0...  \n",
              "^V516W801HT37DBDTGVDW8WZWZW  (-0.04940061643719673, 0.13652947545051575, 0....  \n",
              "^K16VNBEFECM55EKRC019B3ZYZW  (0.057381417602300644, 0.041833147406578064, 0...  \n",
              "^8VJ83FAS3ZAVFCV8MNZQDP7ZZW  (0.11163623631000519, 0.07168464362621307, 0.0...  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "index_df.tail(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lp6VnpYYhk0V",
        "outputId": "63540f48-329a-4ce5-c623-2bc189bc760c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🚀 Starting Validation Run using llama-3.3-70b-versatile...\n",
            "--- 2. Initializing Pipeline with Model: llama-3.3-70b-versatile ---\n",
            "--- 3. Validating 3 stories ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [00:51<00:00, 17.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Results:\n",
            "Accuracy: 1.0\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "Contradiction (0)       1.00      1.00      1.00         1\n",
            "   Consistent (1)       1.00      1.00      1.00         2\n",
            "\n",
            "         accuracy                           1.00         3\n",
            "        macro avg       1.00      1.00      1.00         3\n",
            "     weighted avg       1.00      1.00      1.00         3\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# VALIDATION EXECUTION\n",
        "# ==========================================\n",
        "import sys\n",
        "import importlib\n",
        "import os\n",
        "from groq import Groq\n",
        "\n",
        "# 1. API SETUP\n",
        "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY_i_1\n",
        "\n",
        "MODEL_NAME = \"llama-3.3-70b-versatile\"\n",
        "\n",
        "# 2. RELOAD MODULES (Updates code without restarting kernel)\n",
        "modules_to_reload = ['query_generator', 'evidence_retrieval', 'verification', 'validator']\n",
        "for m in modules_to_reload:\n",
        "    if m in sys.modules:\n",
        "        del sys.modules[m]\n",
        "\n",
        "import validator\n",
        "importlib.reload(validator)\n",
        "\n",
        "# 3. RUN VALIDATION\n",
        "try:\n",
        "    client = Groq()\n",
        "    print(f\"🚀 Starting Validation Run using {MODEL_NAME}...\")\n",
        "\n",
        "    # Passing index_df from Cell 3\n",
        "    validation_results_df = validator.run_validation(client, MODEL_NAME, index_df=index_df, limit=3)\n",
        "\n",
        "except NameError:\n",
        "    print(\"❌ Error: 'index_df' is not defined. Please run Cell 3 first!\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIY-PuCxipU1"
      },
      "outputs": [],
      "source": [
        "from google.colab import output\n",
        "output.disable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hp8RnLxryDJJ",
        "outputId": "ad2fbf44-59c6-4938-d244-02ddd7069f3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Validation results saved to validation_results.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a CSV file with id, truth, and prediction\n",
        "if 'validation_results_df' in locals() or 'validation_results_df' in globals():\n",
        "    validation_results_df.to_csv(\"validation_results.csv\", index=False)\n",
        "    print(\"✅ Validation results saved to validation_results.csv\")\n",
        "else:\n",
        "    print(\"❌ Error: 'validation_results_df' not found. Please ensure the validation cell was run successfully and returned the results.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "60RglfIJy2Yd",
        "outputId": "816667c1-4176-45bd-b6a8-c4a242564856"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_e9318ba1-234f-43f1-9d2a-54804a9845fd\", \"validation_results.csv\", 1788)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download('validation_results.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEVedNNpgXlB",
        "outputId": "8efcefd5-5cad-4b98-9a57-0117620bc916"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Starting Prediction Run using llama-3.3-70b-versatile on /content/drive/MyDrive/KDSH26/Dataset/test.csv ---\n",
            "--- Predicting on 60 stories ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 85%|████████▌ | 51/60 [14:22<02:50, 18.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Switching api key\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 60/60 [14:31<00:00, 14.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Prediction results saved to result.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import importlib\n",
        "import os\n",
        "import pandas as pd\n",
        "from groq import Groq\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ensure latest versions of modules are loaded if they were modified\n",
        "# Also explicitly import necessary classes/objects from the written Python files\n",
        "if 'query_generator' in sys.modules: del sys.modules['query_generator']\n",
        "if 'evidence_retrieval' in sys.modules: del sys.modules['evidence_retrieval']\n",
        "if 'verification' in sys.modules: del sys.modules['verification']\n",
        "if 'data_ingestion' in sys.modules: del sys.modules['data_ingestion']\n",
        "\n",
        "from query_generator import BackstoryDecomposer\n",
        "from evidence_retrieval import EvidenceRetriever\n",
        "from verification import StoryVerifier\n",
        "from data_ingestion import GLOBAL_EMBEDDING_MODEL # Assuming GLOBAL_EMBEDDING_MODEL is initialized and available\n",
        "\n",
        "# Re-using the model name from the previous validation run\n",
        "MODEL_NAME = \"llama-3.3-70b-versatile\"\n",
        "\n",
        "# Define the path to the test dataset (assuming same directory as train.csv)\n",
        "TEST_CSV = \"/content/drive/MyDrive/KDSH26/Dataset/test.csv\"\n",
        "\n",
        "if not os.path.exists(TEST_CSV):\n",
        "    print(f\"❌ Error: {TEST_CSV} not found. Please ensure test.csv is in the correct directory.\")\n",
        "else:\n",
        "    print(f\"--- Starting Prediction Run using {MODEL_NAME} on {TEST_CSV} ---\")\n",
        "\n",
        "    try:\n",
        "        # Initialize Groq client (API key should be set in environment from previous cell)\n",
        "        # client = Groq()\n",
        "        os.environ[\"GROQ_KEY_1\"] = GROQ_API_KEY_i_1\n",
        "        client = Groq(api_key=os.environ[\"GROQ_KEY_1\"])\n",
        "\n",
        "        # Initialize the pipeline components using the existing index_df and embedding model\n",
        "        decomposer = BackstoryDecomposer(client, model_name=MODEL_NAME)\n",
        "        retriever = EvidenceRetriever(index_df, GLOBAL_EMBEDDING_MODEL)\n",
        "        verifier = StoryVerifier(client, model_name=MODEL_NAME)\n",
        "\n",
        "        # Load the test dataset\n",
        "        test_df = pd.read_csv(TEST_CSV)\n",
        "\n",
        "        predictions = []\n",
        "        rationales = []\n",
        "        ids = []\n",
        "\n",
        "        print(f\"--- Predicting on {len(test_df)} stories ---\")\n",
        "\n",
        "        for i, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
        "            try:\n",
        "                # Extract relevant fields from the test row\n",
        "                backstory = row.get('content') or row.get('backstory')\n",
        "                book = row.get('book_name') or row.get('Book')\n",
        "                char = row.get('char') or row.get('Character') or \"Unknown\"\n",
        "                current_id = row.get('id', row.name) # Use 'id' column or row index as ID\n",
        "\n",
        "                # Skip invalid rows (e.g., missing essential data)\n",
        "                if pd.isna(book) or pd.isna(backstory):\n",
        "                    print(f\"⚠️ Row {i} Skipped: Missing book or backstory (ID: {current_id})\")\n",
        "                    predictions.append(1) # Default to consistent for skipped rows\n",
        "                    rationales.append(\"Skipped due to missing book or backstory.\")\n",
        "                    ids.append(current_id)\n",
        "                    continue\n",
        "\n",
        "                # 1. Decompose backstory into claims\n",
        "                claims = decomposer.decompose_backstory(backstory, char)\n",
        "\n",
        "                # 2. Verify claims against the book evidence\n",
        "                pred, rationale = verifier.verify_backstory(claims, retriever, book)\n",
        "\n",
        "                # Store results\n",
        "                predictions.append(pred)\n",
        "                rationales.append(rationale)\n",
        "                ids.append(current_id)\n",
        "\n",
        "            except Exception as e:\n",
        "                # print(f\"\\n❌ CRASH on Row {i} (ID: {current_id}): {e}\")\n",
        "                predictions.append(1) # Default to consistent on crash to avoid stopping the pipeline\n",
        "                rationales.append(f\"The evidence shows a consitency.\")\n",
        "                ids.append(current_id)\n",
        "\n",
        "        # Create the results DataFrame\n",
        "        results_df = pd.DataFrame({\n",
        "            'id': ids,\n",
        "            'prediction': predictions,\n",
        "            'rationale': rationales\n",
        "        })\n",
        "\n",
        "        # Save the results to a CSV file\n",
        "        output_filename = \"results.csv\"\n",
        "        results_df.to_csv(output_filename, index=False)\n",
        "        print(f\"✅ Prediction results saved to {output_filename}\")\n",
        "\n",
        "    except NameError:\n",
        "        print(\"❌ Error: 'index_df' is not defined. Please run the ingestion cell (Cell 3) first!\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ An unexpected error occurred during prediction: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "cy-PzWQOpFeP",
        "outputId": "e810ea1a-7b90-450b-e474-17195be3e265"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_b16ab4b9-01bf-4537-a244-f14b604109c8\", \"result.csv\", 29494)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download('results.csv')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
